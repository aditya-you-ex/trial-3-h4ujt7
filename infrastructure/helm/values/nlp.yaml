################################################################################
# NLP SERVICE HELM VALUES
#
# This file provides the comprehensive configuration for the NLP microservice,
# addressing:
#   1) Task Extraction Accuracy (95%)
#   2) System Reliability (99.9% uptime)
#   3) Resource Optimization (40% improved utilization)
#
# It references:
#   - Internal import: "infrastructure/kubernetes/nlp/deployment.yaml" for
#     "metadata" and "spec" to maintain consistency in naming, replicas, and
#     labels.
#   - External imports:
#       python 3.11-slim
#       fastapi 0.104.0
#       tensorflow 2.14.0
#
# Globals used:
#   - replicaCount: 3
#   - nameOverride: "nlp-service"
#   - fullnameOverride: "taskstream-nlp-service"
#
# Class: NLPServiceConfig
#   description: "Comprehensive Helm values configuration for NLP service deployment"
#   properties:
#     - image
#     - resources
#     - autoscaling
#     - service
#     - podDisruptionBudget
#     - nodeSelector
#     - tolerations
#     - affinity
#
# Constructor:
#   parameters:
#     - environment (str): environment name (e.g., "production")
#     - resourceTier (dict): resource tier settings
#   steps:
#     1) Configure container image and registry
#     2) Set up resource limits and requests
#     3) Configure horizontal pod autoscaling
#     4) Configure service networking and ports
#     5) Configure pod disruption budget
#     6) Configure node affinity and anti-affinity
#     7) Configure tolerations for spot instances
#     8) Set environment-specific variables and secrets
#
# Functions:
#
# generateFullname(name, environment):
#   1) Combine name and environment
#   2) Apply naming convention
#   3) Validate name length/chars
#   4) Return formatted name
#
# configureResources(tier, enableGPU):
#   1) Set CPU limits/requests based on tier
#   2) Adjust memory for ML workloads
#   3) Enable GPU allocation if needed
#   4) Configure huge pages if required
#   5) Set extended monitoring resources
#
# configureHealthChecks(probeConfig):
#   1) Liveness probe with ML model check
#   2) Readiness probe for availability
#   3) Startup probe for model loading
#   4) Custom health metrics endpoints
#   5) Probe timeouts and thresholds
#
# Export: values (type: helm-values)
#   members exposed:
#     - image
#     - resources
#     - autoscaling
#     - service
#     - podDisruptionBudget
#     - healthCheck
#     - affinity
#   purpose: "Complete Helm values configuration for NLP service deployment"
################################################################################

################################################################################
# GLOBAL SETTINGS
################################################################################
replicaCount: 3
nameOverride: "nlp-service"
fullnameOverride: "taskstream-nlp-service"

################################################################################
# IMAGE CONFIGURATION
# - Reflects usage of python:3.11-slim, fastapi:0.104.0, tensorflow:2.14.0
################################################################################
image:
  repository: "myregistry.io/taskstream-nlp"
  tag: "2.14.0"
  pullPolicy: "Always"
  # Additional notes:
  # The base container includes Python 3.11-slim, FastAPI 0.104.0, TensorFlow 2.14.0
  # to support high-performance NLP model serving.

################################################################################
# RESOURCE ALLOCATIONS
# - Ensures ML tasks have sufficient CPU and memory
# - Balanced defaults to maintain expected 95% task extraction accuracy
################################################################################
resources:
  requests:
    cpu: "500m"
    memory: "1Gi"
  limits:
    cpu: "2000m"
    memory: "4Gi"

################################################################################
# AUTOSCALING CONFIGURATION
# - Ensures resource optimization with 40% improvement
# - Adjusts replicas based on CPU usage to keep system at target load
################################################################################
autoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 5
  targetCPUUtilizationPercentage: 70

################################################################################
# SERVICE CONFIGURATION
# - Defines how the NLP service is exposed internally
################################################################################
service:
  type: ClusterIP
  port: 8080
  # Additional keys could include nodePort, annotations, or other overrides

################################################################################
# POD DISRUPTION BUDGET
# - Maintains at least 2 pods during voluntary disruptions
# - Supports 99.9% uptime requirement
################################################################################
podDisruptionBudget:
  enabled: true
  minAvailable: 2

################################################################################
# HEALTH CHECK CONFIGURATION
# - Mapped to the function "configureHealthChecks"
# - Liveness and readiness probes for reliability
################################################################################
healthCheck:
  livenessProbe:
    enabled: true
    path: /health/liveness
    port: 8080
    initialDelaySeconds: 10
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3

  readinessProbe:
    enabled: true
    path: /health/readiness
    port: 8080
    initialDelaySeconds: 5
    periodSeconds: 5
    timeoutSeconds: 3
    failureThreshold: 3

  startupProbe:
    enabled: false
    # Enable if the model loading time is significant
    path: /health/startup
    port: 8080
    initialDelaySeconds: 15
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 6

################################################################################
# NODE SELECTOR
# - Direct pods to specific types of nodes if needed
################################################################################
nodeSelector: {}

################################################################################
# TOLERATIONS
# - Enable scheduling on spot/preemptible instances to optimize costs
################################################################################
tolerations:
  - key: "kubernetes.io/spot"
    operator: "Exists"
    effect: "NoSchedule"
  # Additional tolerations can be added if necessary

################################################################################
# AFFINITY
# - Encourages distribution across zones and ensures no single node becomes a SPOF
################################################################################
affinity:
  nodeAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
        - matchExpressions:
            - key: "kubernetes.io/os"
              operator: In
              values:
                - "linux"

  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchLabels:
              app: "nlp-service"
          topologyKey: "kubernetes.io/hostname"

################################################################################
# REFERENCE TO INTERNAL IMPORT (deployment.yaml)
# - The following fields correspond to:
#   metadata (e.g., name, namespace, labels)
#   spec (e.g., replicas, containers, strategy)
# - Adjustments and overrides for replicas, resources, and container details
#   can be controlled here in values.yaml or in the template logic.
################################################################################
deploymentReference:
  metadataFromImport: "nlp-service"
  specFromImport:
    replicas: 3
    securityContextRunAsNonRoot: true

################################################################################
# END OF NLP HELM VALUES
################################################################################