# =============================================================================
# KUBERNETES METRICS SERVER CONFIGURATION - TASKSTREAM AI PLATFORM
# -----------------------------------------------------------------------------
# FILE DESCRIPTION:
#   This file defines the Metrics Server Deployment, Service, and APIService
#   for collecting container resource utilization metrics (CPU, memory) on
#   each node/pod within the TaskStream AI platform.
# 
# ADDRESSING KEY REQUIREMENTS (FROM JSON SPECIFICATION & TECH SPECS):
# 1) Resource Optimization (Tech Specs/1.2 System Overview/Success Criteria)
#    - The Metrics Server contributes to a ~40% improvement in resource
#      utilization by providing real-time CPU/memory metrics. These metrics
#      enable HPA (Horizontal Pod Autoscaler) to make decisions every 15s.
#
# 2) System Monitoring (Tech Specs/2.4.1 System Monitoring)
#    - Provides essential metrics that integrate with Prometheus,
#      scraping annotations, and secure HTTPS endpoints for analytics.
#
# 3) Scaling Parameters (Tech Specs/2.5.2 Scaling Parameters)
#    - Supplies CPU and memory usage data, enabling autoscaling to maintain
#      < 100 tasks in the queue for critical components such as analytics
#      and NLP services. Uses a resolution of 15s for near-real-time metrics.
#
# 4) High Availability (Tech Specs/2.5.1 Infrastructure Requirements)
#    - Runs as a highly available (HA) deployment with 2 replicas and
#      priorityClassName=system-cluster-critical to ensure continuity
#      and failover capabilities.
#
# EXTERNAL IMPORTS (IE2):
#   - kubernetes (v1.27+)
#   - metrics-server (v0.6.4)
#
# INTERNAL IMPORT (IE1):
#   - resource-quotas.yaml (named import),
#       referencing "ANALYTICS_QUOTAS" and "NLP_QUOTAS" to ensure synergy
#       between allocated resource requests/limits and enforced namespace
#       quotas. The resource requests and limits below must align with the
#       cluster-level constraints declared in "resource-quotas.yaml".
#
# GLOBALS & CONFIG (FROM JSON SPECIFICATION):
#   - METRICS_SERVER_CONFIG:
#       metricResolution: 15s
#       kubeletInsecure: false
#       kubeletPreferred: true
#       useNodeName: true
#       securePort: 8443
#       tlsConfig.insecureSkipVerify: true
#
# EXPORTS (AS PER JSON SPEC):
#   1) metrics-server (Deployment) - HA, security hardened, resource-optimized
#   2) metrics-server-service (Service) - HTTPS endpoint on port 443
#   3) metrics-server-apiservice (APIService) - Official registration for
#      metrics.k8s.io/v1beta1
#
# =============================================================================
# DEPLOYMENT: metrics-server
# =============================================================================
apiVersion: apps/v1
kind: Deployment
metadata:
  name: metrics-server
  namespace: kube-system
  labels:
    app: metrics-server
    taskstream.ai/component: "metrics-collection"
    taskstream.ai/managed-by: "infrastructure-team"
    taskstream.ai/security-tier: "system"
  annotations:
    description: "Highly available metrics server for cluster resource insights"
    taskstream.ai/requirements.resourceOptimization: "true"
    taskstream.ai/requirements.systemMonitoring: "true"
spec:
  # Ensuring high availability with 2 replicas for multi-node resilience.
  replicas: 2
  selector:
    matchLabels:
      app: metrics-server
  template:
    metadata:
      labels:
        app: metrics-server
      annotations:
        # Prometheus will scrape the metrics on port 8443 over HTTPS.
        prometheus.io/scrape: "true"
        prometheus.io/port: "8443"
    spec:
      # The serviceAccountName must exist in the kube-system namespace
      # with permissions to read metrics from nodes/pods.
      serviceAccountName: metrics-server
      priorityClassName: system-cluster-critical
      # We reference partial synergy with "ANALYTICS_QUOTAS" & "NLP_QUOTAS"
      # from resource-quotas.yaml through our resource requests & limits.
      containers:
        - name: metrics-server
          image: registry.k8s.io/metrics-server/metrics-server:v0.6.4
          imagePullPolicy: IfNotPresent
          # Arguments derived from:
          #   - METRICS_SERVER_CONFIG.metricResolution=15s
          #   - METRICS_SERVER_CONFIG.kubeletPreferred=true => InternalIP
          #   - METRICS_SERVER_CONFIG.useNodeName=true => use node status port
          #   - METRICS_SERVER_CONFIG.kubeletInsecure=false => do not pass '--kubelet-insecure-tls'
          args:
            - "--metric-resolution=15s"
            - "--kubelet-preferred-address-types=InternalIP"
            - "--kubelet-use-node-status-port"
            - "--metric-resolution=15s"
          resources:
            requests:
              cpu: "100m"
              memory: "200Mi"
            limits:
              cpu: "300m"
              memory: "500Mi"
          ports:
            - containerPort: 8443
              name: https
              protocol: TCP
          securityContext:
            # Encouraging best security practices:
            #   - Non-root user enforced
            #   - Read-only root filesystem
            #   - Drop all capabilities
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
          volumeMounts:
            - name: tmp
              mountPath: /tmp
      volumes:
        # Temporary filesystem for storing ephemeral data.
        - name: tmp
          emptyDir: {}
---
# =============================================================================
# SERVICE: metrics-server-service
# =============================================================================
apiVersion: v1
kind: Service
metadata:
  name: metrics-server
  namespace: kube-system
  labels:
    app: metrics-server
    taskstream.ai/component: "metrics-collection-service"
    taskstream.ai/managed-by: "infrastructure-team"
    taskstream.ai/security-tier: "system"
  annotations:
    description: "Service exposing the metrics server over HTTPS port 443"
spec:
  selector:
    app: metrics-server
  # Expose port 443 -> targetPort 8443 for secure metrics retrieval
  ports:
    - name: https
      port: 443
      protocol: TCP
      targetPort: 8443
---
# =============================================================================
# APISERVICE: metrics-server-apiservice
# =============================================================================
apiVersion: apiregistration.k8s.io/v1
kind: APIService
metadata:
  # The official name for serving metrics at metrics.k8s.io/v1beta1
  name: v1beta1.metrics.k8s.io
  labels:
    app: metrics-server
    taskstream.ai/component: "metrics-collection-api"
    taskstream.ai/managed-by: "infrastructure-team"
    taskstream.ai/security-tier: "system"
spec:
  group: metrics.k8s.io
  version: v1beta1
  insecureSkipTLSVerify: true
  service:
    name: metrics-server
    namespace: kube-system
  groupPriorityMinimum: 100
  versionPriority: 100